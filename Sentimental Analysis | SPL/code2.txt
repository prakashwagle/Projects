main <- function(){
					library(plyr)
					library(stringr)
					library(e1071) 

					a=read.csv("E:\\Softwares\\email[001]",header = TRUE,check.names=T,stringsAsFactors = FALSE)
					
					a1=a[1:1011,1:15]
					sentences=a1[1:1011,13]
					
					afinn_list <- read.delim(file='E:\\Softwares\\imm6010\\AFINN\\AFINN-111.txt', header=FALSE, stringsAsFactors=FALSE)
					names(afinn_list) <- c('word', 'score')
					afinn_list$word <- tolower(afinn_list$word)    

					vNegTerms <- afinn_list$word[afinn_list$score==-5 | afinn_list$score==-4]
					negTerms <- c(afinn_list$word[afinn_list$score==-3 | afinn_list$score==-2 | afinn_list$score==-1], "second-rate", "moronic", "third-rate", "flawed", "juvenile", "boring", "distasteful", "ordinary", "disgusting", "senseless", "static", "brutal", "confused", "disappointing", "bloody", "silly", "tired", "predictable", "stupid", "uninteresting", "trite", "uneven", "outdated", "dreadful", "bland")
					posTerms <- c(afinn_list$word[afinn_list$score==3 | afinn_list$score==2 | afinn_list$score==1], "first-rate", "insightful", "clever", "charming", "comical", "charismatic", "enjoyable", "absorbing", "sensitive", "intriguing", "powerful", "pleasant", "surprising", "thought-provoking", "imaginative", "unpretentious")
					vPosTerms <- c(afinn_list$word[afinn_list$score==5 | afinn_list$score==4], "uproarious", "riveting", "fascinating", "dazzling", "legendary")  

					x <- sentimentScore(sentences, vNegTerms, negTerms, posTerms, vPosTerms)
sentimentScore <- function(sentences, vNegTerms, negTerms, posTerms, vPosTerms){
					final_scores <- matrix('', 0, 4)
					scores <- laply(sentences, function(sentence, vNegTerms, negTerms, posTerms, vPosTerms)
					{
						initial_sentence <- sentence
						sentence <- gsub('[[:punct:]]', '', sentence)
						sentence <- gsub('[[:cntrl:]]', '', sentence)
						sentence <- gsub('\\d+', '', sentence)
						sentence <- tolower(sentence)
						wordList <- str_split(sentence, '\\s+')
						words <- unlist(wordList)

						vPosMatches <- match(words, vPosTerms)
						posMatches <- match(words, posTerms)
						vNegMatches <- match(words, vNegTerms)
						negMatches <- match(words, negTerms)

						vPosMatches <- sum(!is.na(vPosMatches))
						posMatches <- sum(!is.na(posMatches))
						vNegMatches <- sum(!is.na(vNegMatches))
						negMatches <- sum(!is.na(negMatches))
						score <- c(vNegMatches, negMatches, posMatches, vPosMatches)

						
					return(score)
					}, vNegTerms, negTerms, posTerms, vPosTerms)
					  return(scores)
					}
x1 = x[,1]
					x2 = x[,2]
					x3 = x[,3]
					x4 = x[,4]
					
					y1 = x1 * -5
					y2 = x2* -2
					y3 = x3 * 2
					y4 = x4 * 5

					y = y1 + y2 + y3 + y4
					
					a2 <- data.frame("vNegTerms" = x1, "negTerms" = x2, "posTerms" = x3, "vPosTerms" = x4, "Score" = y)
					a3 <- cbind(a1, a2)
					View(a3)
					a4=sum(y)					


					library(tm)
					library(wordcloud)
					sentences1=a[1:1011,13]
					mail <- Corpus(VectorSource(sentences1))
					w <- wordcloud(mail)
					wordcloud <- function(mail)
					{
					mail <- tm_map(mail, stripWhitespace)
					mail <- tm_map(mail, tolower)
					mail <- tm_map(mail, removeWords, stopwords("english"))
					mail <- tm_map(mail, removeNumbers)
					mail <- tm_map(mail, removePunctuation)
					mail <- tm_map(mail, removeWords,"kuldeep")
					return(as.character(mail))
					}
					d <- data.frame("Sentence" = w)
					write.csv(d,file="E:\\Softwares\\abc1.csv")

					View(d)
					}

					main()
